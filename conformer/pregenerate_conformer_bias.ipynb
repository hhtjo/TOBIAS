{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2024-06-19T08:27:39.504046Z","iopub.status.busy":"2024-06-19T08:27:39.503580Z","iopub.status.idle":"2024-06-19T08:32:04.527349Z","shell.execute_reply":"2024-06-19T08:32:04.526211Z","shell.execute_reply.started":"2024-06-19T08:27:39.504001Z"},"trusted":true},"outputs":[],"source":["from datasets import load_dataset, DatasetDict\n","dataset_name = \"ccdv/cnn_dailymail\"\n","data_size = '100%'\n","splits = ('train', 'validation', 'test')\n","split_tuples = [f\"{split}[:{data_size}]\" for split in splits]\n","data_splits = load_dataset(dataset_name,\n","                           '3.0.0',\n","                            split=split_tuples,\n","                            )\n","cnn = DatasetDict(dict(zip(splits, data_splits)))\n","cnn"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:34:52.601367Z","iopub.status.busy":"2024-06-19T08:34:52.599109Z","iopub.status.idle":"2024-06-19T08:34:59.539608Z","shell.execute_reply":"2024-06-19T08:34:59.538294Z","shell.execute_reply.started":"2024-06-19T08:34:52.601305Z"},"trusted":true},"outputs":[],"source":["from transformers import BartTokenizerFast\n","tokenizer = BartTokenizerFast.from_pretrained(\n","    \"facebook/bart-base\",\n","    bos_token=None,\n","    eos_token=None,\n","    sep_token=None,\n","    cls_token=None,\n","    unk_token=None,\n","    pad_token=None,\n",")"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:34:59.542991Z","iopub.status.busy":"2024-06-19T08:34:59.542238Z","iopub.status.idle":"2024-06-19T08:35:01.365754Z","shell.execute_reply":"2024-06-19T08:35:01.364362Z","shell.execute_reply.started":"2024-06-19T08:34:59.542944Z"},"trusted":true},"outputs":[],"source":["import nltk\n","from nltk.corpus import stopwords\n","nltk.download('stopwords')\n","stop_words = set(stopwords.words('english'))\n","from nltk.stem import WordNetLemmatizer\n","nltk.download('wordnet')\n","wnl = WordNetLemmatizer()\n","\n","def clean_token(token):\n","    return wnl.lemmatize(token.lstrip('Ġ').lower())\n","\n","def text_to_tokens(text):\n","    tokens = [\n","        cleaned for token in tokenizer.tokenize(text)\n","        if (cleaned:= clean_token(token)).isalpha() and not cleaned in stop_words]\n","    return tokens\n","\n","def tokenize_dataset(x):\n","    x['article_tokens'] = text_to_tokens(x['article'])\n","    x['highlights_tokens'] = text_to_tokens(x['highlights'])\n","    x['highlights_tokens'] = [token for token in x['highlights_tokens'] if token != \"ċ\"]\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:35:07.714481Z","iopub.status.busy":"2024-06-19T08:35:07.714007Z","iopub.status.idle":"2024-06-19T08:35:39.740565Z","shell.execute_reply":"2024-06-19T08:35:39.739350Z","shell.execute_reply.started":"2024-06-19T08:35:07.714448Z"},"trusted":true},"outputs":[],"source":["cnn_with_tokens = cnn.map(tokenize_dataset)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:36:29.846881Z","iopub.status.busy":"2024-06-19T08:36:29.846490Z","iopub.status.idle":"2024-06-19T08:36:32.741234Z","shell.execute_reply":"2024-06-19T08:36:32.740057Z","shell.execute_reply.started":"2024-06-19T08:36:29.846850Z"},"trusted":true},"outputs":[],"source":["import gensim\n","dct = gensim.corpora.Dictionary(cnn_with_tokens['train']['article_tokens'])\n","dct.filter_extremes(no_below=5, no_above=0.3, keep_n=10_000)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:36:38.547302Z","iopub.status.busy":"2024-06-19T08:36:38.546345Z","iopub.status.idle":"2024-06-19T08:36:43.523685Z","shell.execute_reply":"2024-06-19T08:36:43.522493Z","shell.execute_reply.started":"2024-06-19T08:36:38.547264Z"},"trusted":true},"outputs":[],"source":["def add_gensim_bow(x):\n","    x['article_gensim_bow'] = dct.doc2bow(x['article_tokens'])\n","    x['highlights_gensim_bow'] = dct.doc2bow(x['highlights_tokens'])\n","    return x\n","\n","cnn_with_bow = cnn_with_tokens.map(add_gensim_bow)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:36:45.562074Z","iopub.status.busy":"2024-06-19T08:36:45.561692Z","iopub.status.idle":"2024-06-19T08:37:26.878418Z","shell.execute_reply":"2024-06-19T08:37:26.876636Z","shell.execute_reply.started":"2024-06-19T08:36:45.562042Z"},"trusted":true},"outputs":[],"source":["lda = gensim.models.ldamulticore.LdaMulticore(cnn_with_bow['train']['article_gensim_bow'], id2word=dct, num_topics=250, workers=4)\n","topic_word_dist = lda.get_topics()"]},{"cell_type":"markdown","metadata":{},"source":["# After LDA training"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:37:34.295911Z","iopub.status.busy":"2024-06-19T08:37:34.295476Z","iopub.status.idle":"2024-06-19T08:38:12.180534Z","shell.execute_reply":"2024-06-19T08:38:12.179210Z","shell.execute_reply.started":"2024-06-19T08:37:34.295872Z"},"trusted":true},"outputs":[],"source":["def get_topic_dist(x):\n","    return lda.get_document_topics(x, 0, 0)\n","\n","def add_topic_dist(x):\n","    x['article_topics_distribution'] = lda.get_document_topics(x['article_gensim_bow'], 0, 0)\n","    x['highlights_topics_distribution'] = lda.get_document_topics(x['highlights_gensim_bow'], 0, 0)\n","    return x\n","\n","cnn_with_topic_distribution = cnn_with_bow.map(add_topic_dist)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:40:23.256051Z","iopub.status.busy":"2024-06-19T08:40:23.255565Z","iopub.status.idle":"2024-06-19T08:40:25.043602Z","shell.execute_reply":"2024-06-19T08:40:25.042361Z","shell.execute_reply.started":"2024-06-19T08:40:23.256014Z"},"trusted":true},"outputs":[],"source":["# If using tf-idf as input data, set filter_tfidf to reduce input space\n","filter_tfidf = False\n","\n","if filter_tfidf:\n","    tfidf_vector_args = {'max_df': 0.25, 'min_df': 0.02}\n","else:\n","    tfidf_vector_args = {'vocabulary': dct.token2id.keys()}\n","\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","vectorizer = TfidfVectorizer(sublinear_tf=True,\n","                             tokenizer = lambda x: x,\n","                             lowercase=False,\n","                             ngram_range=(1, 1),\n","                             **tfidf_vector_args\n","                            )\n","\n","vectorizer.fit(cnn_with_topic_distribution['train']['article_tokens'])\n","vectorizer.get_feature_names_out().shape"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:40:35.020087Z","iopub.status.busy":"2024-06-19T08:40:35.019703Z","iopub.status.idle":"2024-06-19T08:40:35.278562Z","shell.execute_reply":"2024-06-19T08:40:35.277247Z","shell.execute_reply.started":"2024-06-19T08:40:35.020059Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from transformers import BartTokenizerFast\n","\n","tokenizer = BartTokenizerFast.from_pretrained('facebook/bart-base')"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:40:36.396104Z","iopub.status.busy":"2024-06-19T08:40:36.395538Z","iopub.status.idle":"2024-06-19T08:40:36.408384Z","shell.execute_reply":"2024-06-19T08:40:36.407018Z","shell.execute_reply.started":"2024-06-19T08:40:36.396063Z"},"trusted":true},"outputs":[],"source":["def clean_tokens(tokens):\n","    return [clean_token(token) for token in tokens]\n","\n","\n","def tokens_to_weights(tokens, weights, missing_weight=1e-9):\n","    cleaned_tokens = clean_tokens(tokens)\n","    print(cleaned_tokens)\n","    token_ids = [dct.token2id.get(clean_token, -1) for clean_token in cleaned_tokens]\n","    weights_with_missing = np.append(weights, [missing_weight])\n","    token_weights = [weights_with_missing[token_id] for token_id in token_ids]\n","    return token_weights\n","\n","tokens_to_weights(['syrian', 'official', 'gun', '<unk>'], np.random.rand(10000))"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:41:05.925213Z","iopub.status.busy":"2024-06-19T08:41:05.923976Z","iopub.status.idle":"2024-06-19T08:41:05.933533Z","shell.execute_reply":"2024-06-19T08:41:05.932283Z","shell.execute_reply.started":"2024-06-19T08:41:05.925151Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from scipy.sparse import coo_matrix\n","from tqdm import tqdm\n","from sklearn.preprocessing import normalize\n","\n","\n","def get_whole_sparse_matrix(bow_iterable, norm=False):\n","    # Initialize lists to store indices and values\n","    indices = []\n","    values = []\n","\n","    # Iterate over each row of index-value pairs\n","    print('Starting iter')\n","    for row_index, row_pairs in enumerate(tqdm(bow_iterable)):\n","        for col_index, value in row_pairs:\n","            indices.append((int(row_index), int(col_index)))\n","            values.append(value)\n","\n","    # Separate row and column indices\n","    row_indices, col_indices = zip(*indices)\n","\n","    # Determine the shape of the matrix\n","    shape = (max(row_indices) + 1, max(col_indices) + 1)\n","\n","    # Create COO sparse matrix\n","    coo_mat = coo_matrix((values, (row_indices, col_indices)), shape=shape, dtype=np.float32)\n","    if norm:\n","        return normalize(coo_mat, norm=\"l1\")\n","    return coo_mat"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:41:06.222350Z","iopub.status.busy":"2024-06-19T08:41:06.220731Z","iopub.status.idle":"2024-06-19T08:41:08.334939Z","shell.execute_reply":"2024-06-19T08:41:08.333641Z","shell.execute_reply.started":"2024-06-19T08:41:06.222294Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# For Tf-idf input\n","input_data = {\n","    'train':vectorizer.transform(cnn_with_topic_distribution['train']['article_tokens']).astype(np.float32).toarray(),\n","    'validation':vectorizer.transform(cnn_with_topic_distribution['validation']['article_tokens']).astype(np.float32).toarray(),\n","    'test': vectorizer.transform(cnn_with_topic_distribution['test']['article_tokens']).astype(np.float32).toarray()\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:41:09.745929Z","iopub.status.busy":"2024-06-19T08:41:09.745526Z","iopub.status.idle":"2024-06-19T08:41:14.613410Z","shell.execute_reply":"2024-06-19T08:41:14.612240Z","shell.execute_reply.started":"2024-06-19T08:41:09.745899Z"},"scrolled":true,"trusted":true},"outputs":[],"source":["# For bow-input set norm=True to get Bow-Freq, else Bow-count\n","input_data = {\n","    'train':get_whole_sparse_matrix(cnn_with_topic_distribution['train']['article_gensim_bow'], norm=True).toarray(),\n","    'validation':get_whole_sparse_matrix(cnn_with_topic_distribution['validation']['article_gensim_bow'], norm=True).toarray(),\n","    'test': get_whole_sparse_matrix(cnn_with_topic_distribution['test']['article_gensim_bow'], norm=True).toarray()\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:41:26.191368Z","iopub.status.busy":"2024-06-19T08:41:26.190309Z","iopub.status.idle":"2024-06-19T08:41:26.451501Z","shell.execute_reply":"2024-06-19T08:41:26.450252Z","shell.execute_reply.started":"2024-06-19T08:41:26.191325Z"},"trusted":true},"outputs":[],"source":["test_article_dist = get_whole_sparse_matrix(cnn_with_topic_distribution['test']['article_topics_distribution'], norm=False).toarray()\n","test_highglight_dist = get_whole_sparse_matrix(cnn_with_topic_distribution['test']['highlights_topics_distribution'], norm=False).toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:41:36.108239Z","iopub.status.busy":"2024-06-19T08:41:36.107651Z","iopub.status.idle":"2024-06-19T08:41:36.115054Z","shell.execute_reply":"2024-06-19T08:41:36.113725Z","shell.execute_reply.started":"2024-06-19T08:41:36.108171Z"},"trusted":true},"outputs":[],"source":["import numpy as np\n","from scipy.sparse import coo_matrix\n","\n","def convert_topic_distribution(x):\n","    return np.fromiter(map(lambda y: y[1],x), np.float32)\n","\n","def convert_to_numpy(x):\n","    x['highlights_topics_distribution'] = convert_topic_distribution(x['highlights_topics_distribution'])\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:41:44.720535Z","iopub.status.busy":"2024-06-19T08:41:44.719907Z","iopub.status.idle":"2024-06-19T08:41:47.253418Z","shell.execute_reply":"2024-06-19T08:41:47.251769Z","shell.execute_reply.started":"2024-06-19T08:41:44.720488Z"},"trusted":true},"outputs":[],"source":["highlights_topics_distributions = cnn_with_topic_distribution.map(\n","                                                    convert_to_numpy, num_proc=4,keep_in_memory=True,\n","                                                    remove_columns=['article',\n","                                                                    'highlights',\n","                                                                    'id', \n","                                                                    'article_tokens', \n","                                                                    'highlights_tokens',\n","                                                                    'highlights_gensim_bow',\n","                                                                    'article_gensim_bow',\n","                                                                    'article_topics_distribution']\n","                                                ).with_format(\n","                                                    type=\"numpy\",\n","                                                    columns=[\n","                                                            \"highlights_topics_distribution\",\n","                                                            ]\n","                                                       )\n","highlights_topics_distributions"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:04:53.639733Z","iopub.status.busy":"2024-06-19T09:04:53.638567Z","iopub.status.idle":"2024-06-19T09:04:53.655729Z","shell.execute_reply":"2024-06-19T09:04:53.654321Z","shell.execute_reply.started":"2024-06-19T09:04:53.639680Z"},"trusted":true},"outputs":[],"source":["target_data = {\n","    'train': highlights_topics_distributions['train']['highlights_topics_distribution'],\n","    'test': highlights_topics_distributions['test']['highlights_topics_distribution'],\n","    'validation': highlights_topics_distributions['validation']['highlights_topics_distribution']\n","}"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:42:08.938379Z","iopub.status.busy":"2024-06-19T08:42:08.937915Z","iopub.status.idle":"2024-06-19T08:42:08.948466Z","shell.execute_reply":"2024-06-19T08:42:08.947102Z","shell.execute_reply.started":"2024-06-19T08:42:08.938339Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import Dataset\n","\n","# Due to memory constraints the per word weights target has to be calculated on the fly with the SpaceEfficientTopiDataset\n","\n","class SpaceEfficientTopicDataset(Dataset):\n","    def __init__(self, data, labels):\n","        self.data = data\n","        self.labels = labels\n","    \n","    def __len__(self):\n","        return self.data.shape[0]\n","    \n","    def __getitem__(self, idx):\n","        return self.data[idx], self.labels[idx] @ topic_word_dist\n","\n","class TopicDistributionDataset(Dataset):\n","    def __init__(self, data, labels):\n","        self.data = data\n","        self.labels = labels\n","    \n","    def __len__(self):\n","        return self.data.shape[0]\n","    \n","    def __getitem__(self, idx):\n","        return self.data[idx], self.labels[idx]"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:44:08.088469Z","iopub.status.busy":"2024-06-19T08:44:08.087975Z","iopub.status.idle":"2024-06-19T08:44:08.101099Z","shell.execute_reply":"2024-06-19T08:44:08.099537Z","shell.execute_reply.started":"2024-06-19T08:44:08.088430Z"},"trusted":true},"outputs":[],"source":["from typing import Any, Callable\n","import numpy as np\n","import torch\n","import torchmetrics\n","\n","def intersect(x, y):\n","        a_cat_b, counts = torch.cat([x, y]).unique(return_counts=True)\n","        intersection = a_cat_b[torch.where(counts.gt(1))]\n","        return intersection\n","\n","\n","class TopKMetric:\n","    def __init__(self,k, device='cuda', **kwargs: Any) -> None:\n","        super().__init__(**kwargs)\n","        self.k = k\n","        self.mse = torchmetrics.MeanSquaredError().to(device)\n","        self.cross_entropy = torch.nn.CrossEntropyLoss().to(device)\n","    \n","    def __call__(self, input: torch.FloatTensor, target: torch.FloatTensor) -> Any:\n","        top_input = torch.topk(input, self.k)\n","        top_target = torch.topk(target, self.k)\n","        overlapping_indices = np.mean([len(intersect(x,y)) for x, y in zip(top_input.indices, top_target.indices)])\n","        top_input_vals = input.gather(1, top_target.indices)\n","        return {\n","            \"num_overlapping_indices\": overlapping_indices,\n","            \"mse\": self.mse(top_input_vals, top_target.values),\n","            \"cross_entropy\": self.cross_entropy(top_input_vals, top_target.values),\n","        }"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:22:10.715621Z","iopub.status.busy":"2024-06-19T09:22:10.715080Z","iopub.status.idle":"2024-06-19T09:22:10.724848Z","shell.execute_reply":"2024-06-19T09:22:10.723565Z","shell.execute_reply.started":"2024-06-19T09:22:10.715583Z"},"trusted":true},"outputs":[],"source":["from torch.utils.data import DataLoader\n","\n","def make_loader(dataset_input, dataset_output, batch_size, shuffle=False):\n","    # Change the dataset here according to which target to use, Topics or Word Weights\n","    topic_dataset = TopicDistributionDataset(dataset_input, dataset_output)\n","    return DataLoader(\n","        topic_dataset, batch_size=batch_size, shuffle=shuffle, num_workers=4, pin_memory=True\n","    )\n","\n","data_config = {\n","    \"batch_size\": 500\n","}\n","train_loader = make_loader(input_data['train'], target_data['train'], data_config[\"batch_size\"], True)\n","test_loader = make_loader(input_data['test'], target_data['test'], data_config[\"batch_size\"])\n","val_loader = make_loader(input_data['validation'], target_data['validation'], data_config[\"batch_size\"])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from typing import Any\n","from torch import nn, Tensor\n","import torch\n","import logging\n","\n","\n","class TopicFeedForward(nn.Module):\n","    def __init__(\n","        self,\n","        input_size: int,\n","        hidden_size: int,\n","        output_size: int,\n","        hidden_activation_function = None,\n","        output_activation_function = None,\n","        input_dropout = None,\n","        hidden_dropout = None\n","    ):\n","        super(TopicFeedForward, self).__init__()\n","        self.fc1 = nn.Linear(input_size, hidden_size)\n","        self.fc2 = nn.Linear(hidden_size, output_size)\n","\n","        self.hidden_activation_function = None\n","        self.output_activation_function = None\n","\n","        if hidden_activation_function is not None:\n","            self.hidden_activation_function = hidden_activation_function()\n","        if output_activation_function is not None:\n","            self.output_activation_function = output_activation_function()\n","        \n","        self.hidden_dropout = None\n","        self.input_dropout = None\n","        if hidden_dropout is not None and hidden_dropout > 0:\n","            self.hidden_dropout = torch.nn.Dropout(hidden_dropout)\n","        if input_dropout is not None and input_dropout > 0:\n","            self.input_dropout = torch.nn.Dropout(input_dropout)\n","\n","        #self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","        #self.to(self.device)\n","\n","        self.logger = logging.getLogger(self.__class__.__name__)\n","\n","        self.logger.info(\n","            f\"Initialized TopicFeedForward with input_size: {input_size}, hidden_size: {hidden_size}, output_size: {output_size}\"\n","        )\n","\n","    def forward(self, x: Tensor):\n","        if self.input_dropout is not None:\n","            x = self.input_dropout(x)\n","        out = self.fc1(x)\n","        if self.hidden_activation_function is not None:\n","            out = self.hidden_activation_function(out)\n","        if self.hidden_dropout is not None:\n","            out = self.hidden_dropout(out)\n","        out = self.fc2(out)\n","        if self.output_activation_function is not None:\n","            out = self.output_activation_function(out)\n","        return out"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from typing import Any, Callable\n","import torch\n","import wandb\n","import torchmetrics\n","from pytorch_lightning import LightningModule\n","from huggingface_hub import PyTorchModelHubMixin\n","\n","\n","class Metric:\n","    def __init__(\n","        self,\n","        name: str,\n","        function: Callable,\n","        on_epoch: bool,\n","        for_steps: set[str],\n","    ) -> None:\n","        self.name = name\n","        self.function = function\n","        self.on_epoch = on_epoch\n","        self.for_steps = for_steps\n","\n","\n","class LitTopicFeedForward(LightningModule, PyTorchModelHubMixin):\n","    def __init__(\n","        self,\n","        input_size: int,\n","        hidden_size: int,\n","        output_size: int,\n","        hidden_activation_function=None,\n","        output_activation_function=None,\n","        loss: Any = torch.nn.CrossEntropyLoss,\n","        optimizer: Any = torch.optim.Adam,\n","        learning_rate: float = 0.001,\n","        dropout=0.2,\n","        custom_metrics: list[Metric] = None,\n","    ):\n","        super(LitTopicFeedForward, self).__init__()\n","        self.model = TopicFeedForward(\n","            input_size,\n","            hidden_size,\n","            output_size,\n","            hidden_activation_function,\n","            output_activation_function,\n","            input_dropout=dropout,\n","            hidden_dropout=dropout,\n","        )\n","        self.loss = loss()\n","        self.optimizer = optimizer\n","        self.learning_rate = learning_rate\n","\n","        self._mse = torchmetrics.MeanSquaredError()\n","        self._cross_entropy = torch.nn.CrossEntropyLoss()\n","\n","        self._all_steps = {\"train\", \"val\", \"test\"}\n","\n","        default_metrics = [\n","            Metric(\"mse\", self._mse, True, self._all_steps),\n","            Metric(\"cross_entropy\", self._cross_entropy, True, self._all_steps),\n","        ]\n","        self.metrics = default_metrics + (\n","            custom_metrics if custom_metrics is not None else []\n","        )\n","\n","        self.save_hyperparameters()\n","\n","    def forward(self, x: torch.Tensor) -> torch.Tensor:\n","        return self.model(x)\n","\n","    def _compute_metrics(self, batch, step_name: str) -> Any:\n","        x, y = batch\n","        y_hat = self(x)\n","        loss = self.loss(y_hat, y)\n","        self.log(f\"{step_name}_loss\", loss, on_epoch=True)\n","        for metric in self.metrics:\n","            if step_name in metric.for_steps:\n","                metric_value = metric.function(y_hat, y)\n","                if isinstance(metric_value, dict):\n","                    for key, value in metric_value.items():\n","                        self.log(\n","                            f\"{step_name}_{metric.name}_{key}\",\n","                            value,\n","                            on_epoch=metric.on_epoch,\n","                        )\n","                else:\n","                    self.log(\n","                        f\"{step_name}_{metric.name}\",\n","                        metric_value,\n","                        on_epoch=metric.on_epoch,\n","                    )\n","        return loss\n","\n","    def training_step(self, batch: Any, batch_idx: int) -> Any:\n","        return self._compute_metrics(batch, \"train\")\n","\n","    def validation_step(self, batch: Any, batch_idx: int) -> Any:\n","        return self._compute_metrics(batch, \"val\")\n","\n","    def test_step(self, batch: Any, batch_idx: int) -> Any:\n","        return self._compute_metrics(batch, \"test\")\n","\n","    def on_test_epoch_end(self) -> None:\n","        dummy_input = torch.randn(1, self.hparams.input_size)\n","        model_filename = f\"topic_feedforward_final.onnx\"\n","        self.to_onnx(model_filename, input_sample=dummy_input, export_params=True)\n","\n","        artifact = wandb.Artifact(name=\"model_final.ckpt\", type=\"model\")\n","        artifact.add_file(model_filename)\n","        self.logger.experiment.log_artifact(artifact)\n","\n","    def configure_optimizers(self) -> Any:\n","        return self.optimizer(self.model.parameters(), lr=self.learning_rate)\n"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:22:11.679774Z","iopub.status.busy":"2024-06-19T09:22:11.679324Z","iopub.status.idle":"2024-06-19T09:22:37.358692Z","shell.execute_reply":"2024-06-19T09:22:37.356902Z","shell.execute_reply.started":"2024-06-19T09:22:11.679739Z"},"trusted":true},"outputs":[],"source":["import wandb\n","from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n","import torch\n","import pytorch_lightning as pl\n","import torch\n","import numpy as np\n","pl.seed_everything(42)\n","\n","\n","wandb.init(\n","    mode='offline',\n","    name='bow_normalized_in_topics_out',\n","    project=\"ff_attempts\",\n","\n","    # track hyperparameters and run metadata\n","    config={\n","        \"input\": \"article_bow\",\n","        \"target\": \"topic_dist\",\n","        \"input_shape\": 10_000,\n","        \"outpt_shape\": 250\n","    }\n",")\n","\n","wandb_logger = pl.loggers.WandbLogger(log_model=\"all\")\n","\n","model_config = {\n","    # Change based on input size\n","    \"input_size\": 10_000,\n","    # The same number of hidden nodes as in the CONFORMER\n","    \"hidden_size\": 300,\n","    # Change based on output size\n","    \"output_size\":  250,\n","    \"hidden_activation_function\": None,\n","    \"output_activation_function\": None,\n","    \"loss\": torch.nn.CrossEntropyLoss,\n","    \"dropout\": None,\n","    \"optimizer\": torch.optim.Adam,\n","    \"custom_metrics\": [\n","        Metric(\"topk3\", TopKMetric(3), True, {'val', 'test'}),\n","        Metric(\"topk5\", TopKMetric(5), True, {'val', 'test'}),\n","        Metric(\"topk10\", TopKMetric(10), True, {'val', 'test'}),\n","    ]\n","}\n","\n","stopping_callback = EarlyStopping(monitor=\"val_cross_entropy\", patience=4, verbose=False, mode=\"min\")\n","\n","training_config= {\n","    \"max_epochs\": 15,\n","    \"callbacks\": [stopping_callback],\n","    \"log_every_n_steps\":25,\n","    \"deterministic\":True,\n","    \"detect_anomaly\":False,\n","    \"val_check_interval\":0.5,\n","}\n","trainer = pl.Trainer(\n","    logger=wandb_logger,\n","    **training_config\n",")\n","\n","model = LitTopicFeedForward(**model_config)\n","\n","wandb_logger.watch(model, log=\"all\")\n","\n","trainer.fit(model, train_dataloaders=train_loader, val_dataloaders=val_loader)\n","trainer.test(model, dataloaders=test_loader)"]},{"cell_type":"markdown","metadata":{},"source":["# Generate weights for CONFORMER"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:07:36.723512Z","iopub.status.busy":"2024-06-19T09:07:36.722988Z","iopub.status.idle":"2024-06-19T09:07:36.735133Z","shell.execute_reply":"2024-06-19T09:07:36.733450Z","shell.execute_reply.started":"2024-06-19T09:07:36.723472Z"},"trusted":true},"outputs":[],"source":["import pandas as pd\n","from gensim.models.ldamodel import LdaModel\n","from gensim.corpora import Dictionary\n","\n","# returns a Pandas DataFrame of the NEWTS testing set\n","def read_test(path=\"nortsformer/topic_model/lda/NEWTS_test_600.csv\"):\n","    out = pd.read_csv(path, encoding='utf-8', index_col=[0])\n","    assert(len(out) == 600)\n","    return out\n","\n","# returns a Pandas DataFrame of the NEWTS training set\n","def read_train(path=\"nortsformer/topic_model/lda/NEWTS_train_2400.csv\"):\n","    out = pd.read_csv(path, encoding='utf-8', index_col=[0])\n","    assert(len(out) == 2400)\n","    return out"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:07:37.093067Z","iopub.status.busy":"2024-06-19T09:07:37.092632Z","iopub.status.idle":"2024-06-19T09:07:37.266936Z","shell.execute_reply":"2024-06-19T09:07:37.265666Z","shell.execute_reply.started":"2024-06-19T09:07:37.093033Z"},"trusted":true},"outputs":[],"source":["newts_test = read_test()\n","newts_train = read_train()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:07:37.724055Z","iopub.status.busy":"2024-06-19T09:07:37.723601Z","iopub.status.idle":"2024-06-19T09:07:37.793674Z","shell.execute_reply":"2024-06-19T09:07:37.792281Z","shell.execute_reply.started":"2024-06-19T09:07:37.724016Z"},"trusted":true},"outputs":[],"source":["import datasets\n","hf_newts_test = datasets.Dataset.from_pandas(newts_test, preserve_index=False)\n","hf_newts_train = datasets.Dataset.from_pandas(newts_train, preserve_index=False)\n","hf_newts_train"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:07:38.344286Z","iopub.status.busy":"2024-06-19T09:07:38.343395Z","iopub.status.idle":"2024-06-19T09:07:38.900640Z","shell.execute_reply":"2024-06-19T09:07:38.899345Z","shell.execute_reply.started":"2024-06-19T09:07:38.344231Z"},"trusted":true},"outputs":[],"source":["def separate_samples(newts_dataset):\n","    newts_separated = []\n","    for x in newts_dataset:\n","        sample1 = {\n","            'id': x['AssignmentId'] + \"_1\",\n","            'article': x['article'],\n","            'sentence': x['sentences1'],\n","            'summary': x['summary1']\n","        }\n","        sample2 = {\n","            'id': x['AssignmentId'] + \"_2\",\n","            'article': x['article'],\n","            'sentence': x['sentences2'],\n","            'summary': x['summary2']\n","        }\n","        newts_separated.extend([sample1, sample2])\n","    return datasets.Dataset.from_pandas(pd.DataFrame(data=newts_separated))\n","newts_cleaned = datasets.DatasetDict(\n","    {'test':separate_samples(hf_newts_test),\n","    'train':separate_samples(hf_newts_train)\n","    }\n",")\n","newts_cleaned"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:07:39.762821Z","iopub.status.busy":"2024-06-19T09:07:39.762372Z","iopub.status.idle":"2024-06-19T09:07:39.770935Z","shell.execute_reply":"2024-06-19T09:07:39.769655Z","shell.execute_reply.started":"2024-06-19T09:07:39.762786Z"},"trusted":true},"outputs":[],"source":["def tokenize_newts(x):\n","    x['sentence_plus_article_tokens'] = text_to_tokens(x['sentence'] + \" \" + x['article'])\n","    return x"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:07:40.169065Z","iopub.status.busy":"2024-06-19T09:07:40.168653Z","iopub.status.idle":"2024-06-19T09:08:01.662848Z","shell.execute_reply":"2024-06-19T09:08:01.661256Z","shell.execute_reply.started":"2024-06-19T09:07:40.169035Z"},"trusted":true},"outputs":[],"source":["newts_with_tokens = newts_cleaned.map(tokenize_newts, num_proc=4)\n","newts_with_tokens"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:58:18.927668Z","iopub.status.busy":"2024-06-19T08:58:18.926254Z","iopub.status.idle":"2024-06-19T08:58:25.890761Z","shell.execute_reply":"2024-06-19T08:58:25.889663Z","shell.execute_reply.started":"2024-06-19T08:58:18.927566Z"},"trusted":true},"outputs":[],"source":["def add_gensim_bow(x):\n","    x['gensim_bow'] = dct.doc2bow(x['sentence_plus_article_tokens'])\n","    return x\n","newts_with_bow = newts_with_tokens.map(add_gensim_bow)\n","newts_with_bow"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T08:58:28.407117Z","iopub.status.busy":"2024-06-19T08:58:28.406646Z","iopub.status.idle":"2024-06-19T08:58:35.806580Z","shell.execute_reply":"2024-06-19T08:58:35.805234Z","shell.execute_reply.started":"2024-06-19T08:58:28.407080Z"},"trusted":true},"outputs":[],"source":["train_bow = get_whole_sparse_matrix(newts_with_bow['train']['gensim_bow'], norm=True).toarray()\n","test_bow = get_whole_sparse_matrix(newts_with_bow['test']['gensim_bow'], norm=True).toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-05-24T12:32:18.571892Z","iopub.status.busy":"2024-05-24T12:32:18.570925Z","iopub.status.idle":"2024-05-24T12:32:23.412549Z","shell.execute_reply":"2024-05-24T12:32:23.410548Z","shell.execute_reply.started":"2024-05-24T12:32:18.571854Z"},"trusted":true},"outputs":[],"source":["train_tfid = vectorizer.transform(newts_with_bow['train']['sentence_plus_article_tokens']).astype(np.float32).toarray()\n","test_tfid = vectorizer.transform(newts_with_bow['test']['sentence_plus_article_tokens']).astype(np.float32).toarray()"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["def get_document_topics_from_lda(x):\n","    x['document_topics'] = lda.get_document_topics(x['gensim_bow'], 0, 0)\n","    return x\n","newts_with_lda_topics = newts_with_bow.map(get_document_topics_from_lda)"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:01:05.957961Z","iopub.status.busy":"2024-06-19T09:01:05.957427Z","iopub.status.idle":"2024-06-19T09:01:06.635310Z","shell.execute_reply":"2024-06-19T09:01:06.633970Z","shell.execute_reply.started":"2024-06-19T09:01:05.957919Z"},"trusted":true},"outputs":[],"source":["import torch.nn.functional as F\n","# If model output is topics\n","test_result = F.softmax(model(torch.from_numpy(test_bow))).detach().numpy() @ topic_word_dist\n","train_result = F.softmax(model(torch.from_numpy(train_bow))).detach().numpy() @ topic_word_dist"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# If model putput is word weights\n","test_result = model(torch.from_numpy(test_bow)).detach().numpy()\n","train_result = model(torch.from_numpy(train_bow)).detach().numpy()"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:01:10.329657Z","iopub.status.busy":"2024-06-19T09:01:10.329242Z","iopub.status.idle":"2024-06-19T09:01:10.853614Z","shell.execute_reply":"2024-06-19T09:01:10.852253Z","shell.execute_reply.started":"2024-06-19T09:01:10.329627Z"},"trusted":true},"outputs":[],"source":["test_tau_data = datasets.Dataset.from_dict({\"tau\": test_result})\n","test_final = datasets.concatenate_datasets([newts_with_bow['test'], test_tau_data], axis=1).remove_columns(['sentence_plus_article_tokens', 'gensim_bow'])\n","train_tau_data = datasets.Dataset.from_dict({\"tau\": train_result})\n","train_final = datasets.concatenate_datasets([newts_with_bow['train'], train_tau_data], axis=1).remove_columns(['sentence_plus_article_tokens', 'gensim_bow'])"]},{"cell_type":"code","execution_count":null,"metadata":{"execution":{"iopub.execute_input":"2024-06-19T09:01:11.929457Z","iopub.status.busy":"2024-06-19T09:01:11.929040Z","iopub.status.idle":"2024-06-19T09:01:11.937489Z","shell.execute_reply":"2024-06-19T09:01:11.936005Z","shell.execute_reply.started":"2024-06-19T09:01:11.929426Z"},"trusted":true},"outputs":[],"source":["final_dataset = datasets.DatasetDict(\n","    {\n","        'train': train_final,\n","        'test': test_final\n","    }\n",")\n","final_dataset.save_to_disk(\"../dataset/NEWTS_with_tau\")"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30698,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"}},"nbformat":4,"nbformat_minor":4}
